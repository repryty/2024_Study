{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인공 신경망 구조 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\repry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\repry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: torch==2.3.0 in c:\\users\\repry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (2.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\repry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\repry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\repry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\repry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\repry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\repry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\repry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\repry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\repry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\repry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\repry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\repry\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'iterator' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m      8\u001b[0m dataiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_data) \u001b[38;5;66;03m# iterator\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mdataiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m()\n\u001b[0;32m     11\u001b[0m imshow(torchvision\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mmake_grid(images))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'iterator' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    # img = img / 2 + 0.5     # denormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(train_data) # iterator\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "loss: -0.27907595038414\n",
      "tensor([[ 0.0177,  0.0106,  0.0129,  ...,  0.0066, -0.0196, -0.0165],\n",
      "        [-0.0052,  0.0302, -0.0050,  ...,  0.0348, -0.0267, -0.0127],\n",
      "        [ 0.0152,  0.0307, -0.0270,  ...,  0.0119,  0.0083, -0.0011],\n",
      "        ...,\n",
      "        [-0.0223,  0.0189, -0.0187,  ..., -0.0190,  0.0095, -0.0134],\n",
      "        [-0.0190, -0.0013,  0.0349,  ..., -0.0036,  0.0265, -0.0180],\n",
      "        [-0.0064, -0.0289,  0.0264,  ...,  0.0250, -0.0117, -0.0133]])\n",
      "tensor([ 0.0311, -0.0061,  0.0264,  ...,  0.0186,  0.0329, -0.0149])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torchvision\n",
    "\n",
    "transform=torchvision.transforms.ToTensor()\n",
    "train_data = torchvision.datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_data = torchvision.datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "print(train_data)\n",
    "\n",
    "# Write neural network code\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.input_layer = nn.Linear(784, 1568)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.hidden_layers = [nn.Linear(1568, 1568) for _ in range(1)]\n",
    "        self.output_layer = nn.Linear(1568, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.activation(x)\n",
    "        for i in self.hidden_layers:\n",
    "            x=i(x)\n",
    "            self.activation(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Define the network and the loss function.\n",
    "network = NeuralNetwork()\n",
    "# loss_function = nn.MSELoss()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Steps for gradient descent.\n",
    "# 'lr' stands for learning rate.\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "# Training one step with sample data\n",
    "x = train_data[2][0].view(1, 784)\n",
    "y = [0 for i in range(10)]\n",
    "y[train_data[2][1]]=1\n",
    "y = torch.Tensor(y)\n",
    "y= y.view(1,10)\n",
    "\n",
    "\n",
    "optimizer.zero_grad()\n",
    "output = network(x)\n",
    "# print(output.shape, y.shape)\n",
    "loss = loss_function(y, output)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# Check parameters\n",
    "parameters = network.input_layer.state_dict()\n",
    "w = parameters['weight']  # e.g. [-5, -1.2, 1.2, 1.2, 2, 5]\n",
    "b = parameters['bias']  # e.g. [-7.7, -1.3, 1, -0.2, -1.1, -5]\n",
    "print(f\"loss: {loss}\")\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.612:  69%|██████▉   | 34699/50000 [11:10<04:55, 51.72it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[135], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m output \u001b[38;5;241m=\u001b[39m network(x)\n\u001b[0;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(output, y)\n\u001b[1;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\repry\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\repry\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\repry\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import numpy\n",
    "\n",
    "# Define the network and the loss function.\n",
    "network = NeuralNetwork()\n",
    "# loss_function = nn.MSELoss()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "pbar = tqdm(range(50000), desc=\"Loss: --\")\n",
    "for epoch in pbar:\n",
    "    test_case=random.randint(0, 59999)\n",
    "    x = train_data[test_case][0].view(1, 784)\n",
    "    y = [0 for i in range(10)]\n",
    "    y[train_data[test_case][1]]=1\n",
    "    y = torch.Tensor(y)\n",
    "    y= y.view(1,10)\n",
    "    # time.sleep(1)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = network(x)\n",
    "    loss = loss_function(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        pbar.set_description(f\"Loss: {loss.item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: -14.979963302612305, output: tensor([-6.0854, 14.5195, -5.5369, -1.3197, -0.7551, -6.0401, -0.6027,  2.7124,\n",
      "         1.0213,  1.8996], grad_fn=<SelectBackward0>), answer: tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = test_data[2][0].view(1, 784)\n",
    "y = [0 for i in range(10)]\n",
    "y[test_data[2][1]]=1\n",
    "y = torch.Tensor(y)\n",
    "y= y.view(1,10)\n",
    "\n",
    "\n",
    "optimizer.zero_grad()\n",
    "output = network(x)\n",
    "loss = loss_function(y, output)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "print(f\"loss: {loss}, output: {(output[0])}, answer: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.974: 100%|██████████| 5000/5000 [01:37<00:00, 51.30it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.830566113222645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "end=0\n",
    "pbar = tqdm(range(5000), desc=\"Loss: --\")\n",
    "for epoch in pbar:\n",
    "    x = test_data[epoch][0].view(1, 784)\n",
    "    y = [0 for i in range(10)]\n",
    "    y[test_data[epoch][1]]=1\n",
    "    y = torch.Tensor(y)\n",
    "    y= y.view(1,10)\n",
    "    # time.sleep(1)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = network(x)\n",
    "    loss = loss_function(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    output=output.tolist()[0]\n",
    "    \n",
    "    if output.index(max(output))==test_data[epoch][1]:\n",
    "        end+=1\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        pbar.set_description(f\"Loss: {loss.item():.3f}\")\n",
    "\n",
    "print(end/epoch*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((output.detach().numpy()))\n",
    "type(numpy.array([1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.09532588, 0.13042647, 0.08980362, 0.13609603, 0.0969222 ,\n",
       "        0.12474118, 0.06336303, 0.1024522 , 0.0912748 , 0.07248389],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.detach().numpy().tolist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Type must be a sub-type of ndarray type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m numpy_array \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), output\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[1;31mValueError\u001b[0m: Type must be a sub-type of ndarray type"
     ]
    }
   ],
   "source": [
    "numpy_array = output.detach().numpy()\n",
    "plt.plot(numpy.array([i for i in range(10)]).view(1, 10).detach().numpy(), output.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the result\n",
    "x_lim = 5\n",
    "num_points = 1\n",
    "\n",
    "x = torch.linspace(-x_lim, x_lim, num_points)\n",
    "y = x**3 + x**2 - x - 1\n",
    "# y= x**4-14*x**3-83*x**2+168*x+540\n",
    "plt.plot(x, y, label=\"ground truth\", color=\"black\")\n",
    "plt.plot(x, network(x[:, None]).detach().numpy(), label=\"prediction\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
