{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/repryty/2024_Study/blob/main/bandit-example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuDaRw3aGf17"
      },
      "source": [
        "# 강화 학습 환경 복습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qCAXPrHGf1_",
        "outputId": "339faf89-ad38-4f8b-b7ec-01447c79244c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium[classic-control]\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (4.10.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium[classic-control])\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (2.5.2)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium[classic-control]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2vY1zCFGf2A"
      },
      "source": [
        "### 강화 학습 문제를 직접 풀어낼 정책 정의\n",
        "\n",
        "강화 학습에서는 어떤 함수를 학습하고자 하는 걸까요? 에이전트 안에는 상태 관측값(입력)을 받고 그것을 앞으로 취해야 할 최적의 행동(출력)에 매핑하는 함수가 있습니다. 예를 들어, 미로 속 에이전트의 현재 상태가 $(2, 3)$ 좌표라면, 에이전트 안의 함수는 이 입력값을 \"오른쪽으로 이동\"이라는 출력값에 매핑하는 것이 될 수 있습니다. 이 함수를 $\\pi$라고 한다면, 아래와 같이 수식으로 쓸 수 있습니다.\n",
        "$$\n",
        "\\pi((2, 3)) = \\text{\"오른쪽으로 이동\"}\n",
        "$$\n",
        "강화 학습 용어로 이 함수를 정책(policy)이라고 부릅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQVpDtbyGf2B"
      },
      "outputs": [],
      "source": [
        "def policy(state):\n",
        "    x_position = state[0]\n",
        "    x_velocity = state[1]\n",
        "\n",
        "    if x_velocity > 0:\n",
        "        action = 2\n",
        "    elif x_velocity < 0:\n",
        "        action = 0\n",
        "    else:\n",
        "        if x_position > -0.6:\n",
        "            action = 0\n",
        "        else:\n",
        "            action = 2\n",
        "\n",
        "    return action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMAngzWEGf2C"
      },
      "source": [
        "### 강화 학습이 돌아가는 환경의 코드 복습\n",
        "\n",
        "1. 인공지능 모델은 환경의 현재 상태(state)를 관찰할 수 있습니다. 미로 찾기 문제에서 환경의 현재 상태란 미로 속 현재 위치를 의미합니다. 예를 들어, 모델이 미로의 $(2, 3)$ 좌표에 있다면, 이 좌표는 현재 상태를 나타냅니다.\n",
        "\n",
        "2. 인공지능 모델은 관찰된 상태로부터 앞으로 취할 행동(action)을 결정합니다. 양갈래 길 중에서 어디로 갈지 결정하는 것 등이 그 예시가 될 수 있습니다.\n",
        "\n",
        "3. 환경은 상태를 변경(transition)시키고 그 행동에 대한 보상(reward)을 생성합니다. 인공지능 모델은 그 상태와 보상을 다 받습니다. 미로 찾기 문제에서 환경의 변화란 인공지능 모델의 (앞선 결정에 따른) 미로 속 위치 변화를 의미합니다. 예를 들어, '오른쪽으로 이동' 행동을 취하면, 에이전트의 위치 좌표가 $(2, 3)$에서 $(2, 4)$로 바뀔 수 있습니다. 보상은 출구를 찾았을 때 주어지는 경품이나 막다른 길에 도달했을 때 받는 페널티 등을 생각해 볼 수 있습니다.\n",
        "\n",
        "4.  이 새로운 정보(환경의 변화와 이에 따른 보상)를 사용하여 인공지능은 그런 행동이 좋아 그걸 반복해야 하는지, 또는 좋지 않아 회피해야 하는지 결정할 수 있습니다. 완료될 때까지 (done) 이 관측-행동-보상 사이클은 계속됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3E1Gi4oZGf2C"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "env = gym.make('MountainCar-v0')\n",
        "state, _ = env.reset()\n",
        "print(\"Initial state:\", state)\n",
        "\n",
        "done = False\n",
        "total_reward = 0\n",
        "while not done:\n",
        "    action = policy(state)\n",
        "    print(\"Chose action:\", action)\n",
        "    state, reward, done, _, _ = env.step(action)\n",
        "    total_reward += reward\n",
        "    print(\"New state:\", state)\n",
        "    print(\"Reward:\", reward)\n",
        "\n",
        "print(\"Final state:\", state)\n",
        "print(\"Total reward:\", total_reward)\n",
        "env.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74uFnDQTGf2D"
      },
      "source": [
        "### 환경 직접 만들어보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNRU-Ma0Gf2D"
      },
      "outputs": [],
      "source": [
        "class MyEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        self.observation_space = gym.spaces.Discrete(7, start=-3)\n",
        "        self.action_space = gym.spaces.Discrete(2)\n",
        "        self.num_steps = 0\n",
        "\n",
        "    def reset(self):\n",
        "        state = 0\n",
        "        return state\n",
        "\n",
        "    def step(self, action):\n",
        "        self.num_steps += 1\n",
        "\n",
        "        if action == 0:\n",
        "            next_state = state - 1\n",
        "        else:\n",
        "            next_state = state + 1\n",
        "\n",
        "        if next_state > 3:\n",
        "            next_state = 3\n",
        "        elif next_state < -3:\n",
        "            next_state = -3\n",
        "\n",
        "        reward = {\n",
        "            -3: 1,\n",
        "            -2: 1,\n",
        "            -1: 1,\n",
        "            0: 0,\n",
        "            1: -1,\n",
        "            2: -1,\n",
        "            3: 10\n",
        "        }[next_state]\n",
        "\n",
        "        done = self.num_steps >= 3\n",
        "        return next_state, reward, done, {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHV_E2zzGf2D"
      },
      "outputs": [],
      "source": [
        "class StudentMDP(gym.Env):\n",
        "    def __init__(self):\n",
        "        # 0: 수업, 1: 야자, 2: 집, 3: 잘침, 4: 못침\n",
        "        self.observation_space = gym.spaces.Discrete(5)\n",
        "\n",
        "        # 0: 공부, 1: 딴짓, 2: 땡땡이, 3: 쇼츠보기, 4: 벼락치기, 5: 수면\n",
        "        self.action_space = gym.spaces.Discrete(6)\n",
        "\n",
        "    def reset(self):\n",
        "        state = ???\n",
        "        return state\n",
        "\n",
        "    def step(self, action):\n",
        "        state = ???\n",
        "        reward = ???\n",
        "        done = ???\n",
        "        return state, reward, done, {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI8OFlxmGf2E"
      },
      "source": [
        "# 슬롯머신 정복하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GckfImVaGf2E"
      },
      "source": [
        "### 슬롯머신 환경 구현하기\n",
        "\n",
        "각각의 밴딧 $i = 1, \\cdots, n$에 대해, 먼저 랜덤하게 실제 가치 $\\mu_{i} \\sim N(0, 1)$를 평균 0 분산 1인 표준정규분포에서 추출해 정해줍니다. 그리고 $i$번 째 밴딧을 고를 경우, 받을 수 있는 보상은 다음과 같이 정해줍니다:\n",
        "$$\n",
        "r_{t} = \\mu_{i} + \\varepsilon \\quad \\text{where} \\quad \\varepsilon \\sim N(0, 1)\n",
        "$$\n",
        "즉, $i$번 째 밴딧을 골랐을 때의 보상은, 그 밴딧의 실제 가치 $\\mu_{i}$에 랜덤한 표준 정규 노이즈 $\\varepsilon \\sim N(0, 1)$을 더한 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.normal(size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtnkntszHDVN",
        "outputId": "804e61e6-65c2-41e8-da5a-41d7f48773aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.38577122,  0.47221928, -1.01199908,  0.11869298,  0.72913336,\n",
              "       -1.24429284, -1.27983047, -1.34342005, -0.80751108,  0.40580367])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "a0KseiTnGf2E"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class BanditEnv(gym.Env):\n",
        "    def __init__(self, num_bandits):\n",
        "        self.num_bandits = num_bandits # 슬롯머신의 갯수\n",
        "        self.action_space = list(range(num_bandits)) # 행동은 가능한 모든 슬롯머신\n",
        "        self.observation_space = [0] # 상태는 의미 없음\n",
        "\n",
        "    def reset(self):\n",
        "        # 슬롯머신의 평균 보상의 크기를 미리 결정하는 코드\n",
        "        # 각 슬롯머신에 대해, 랜덤한 평균 보상의 크기를 결정해 줌.\n",
        "        # self.mean = np.random.normal(size=self.num_bandits) * 10\n",
        "\n",
        "        # 아래는 항상 같은 크기의 보상을 정해둔 코드의 예시\n",
        "        # self.mean = [9, 8, 7.5, 7, 8.5, 7, 6, 7.5, 8, 8.5]\n",
        "        self.mean=np.random.normal(size=self.num_bandits) * 10\n",
        "        return 0 # 상태 전환 없음. 의미 없음.\n",
        "\n",
        "    def step(self, action):\n",
        "        state = 0\n",
        "        mean = self.mean[action] # 정해둔 평균값에서 선택한 슬롯머신에 대한 값 확인\n",
        "        reward = mean + np.random.normal() # 보상은 그 슬롯머신의 평균값 + 랜덤한 노이즈\n",
        "        done = False\n",
        "        return state, reward, done, {}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyPolicy:\n",
        "  def __init__(self, num_bandits):\n",
        "    self.num_bandits = num_bandits # 슬롯머신 개수 저장\n",
        "    # 이 아래에 본인이 더 저장하고 싶은 정보 정의 가능!\n",
        "    initial_q=100\n",
        "    self.q = [initial_q for machine in range(num_bandits)]\n",
        "    self.n = [0 for machine in range(num_bandits)]\n",
        "\n",
        "  def __call__(self, state):\n",
        "    action = np.argmax(self.q)\n",
        "    return action"
      ],
      "metadata": {
        "id": "avjFuog8OYpE"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = [1,3,2,1]\n"
      ],
      "metadata": {
        "id": "yTAsa5eLwALP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = BanditEnv(10)\n",
        "state = env.reset()\n",
        "agent = MyPolicy(10)\n",
        "\n",
        "# 그동안의 선택 정보를 저장\n",
        "history = [100 for i in range(env.num_bandits)]\n",
        "num=[1 for i in range(env.num_bandits)]\n",
        "\n",
        "total_reward = 0\n",
        "for t in range(2000):\n",
        "    if np.random.random(1)[0]<=0.01:\n",
        "        action = action=np.random.randint(0, env.num_bandits)\n",
        "    else:\n",
        "        action = agent(state)\n",
        "#   action = np.random.choice(env.num_bandits)\n",
        "    state, reward, done, _ = env.step(action)\n",
        "\n",
        "    # 기록 저장\n",
        "    agent.n[action]+=1\n",
        "    agent.q[action]+= (reward - agent.q[action])/ agent.n[action]\n",
        "    total_reward+=reward\n",
        "\n",
        "    # agent.q = ???\n",
        "    # print(f\"Action: {action}\")\n",
        "    # print(f\"Reward: {reward}\")\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"Total Reward: {total_reward}\")\n",
        "\n",
        "# 기록 플롯\n",
        "import matplotlib.pyplot as plt\n",
        "for machine in range(env.num_bandits):\n",
        "  plt.scatter(range(env.num_bandits), agent.q)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "Xxd0XwHZKVHx",
        "outputId": "80cd37b2-dc73-4904-842f-36397fd940b9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Reward: 49996.76033137486\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGdCAYAAAA8F1jjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAiGklEQVR4nO3df3ST5f3/8dedQgtoG5q2tHIs2OoGA53ywyI4/aByoDvoOcJOnR6dqIDthlNAna2d4I+VAG7omTJa1gIep0fHGbi575EjY07nBKu4sulEZVRhYAtNQwLsLNXm/v7BiMS2GEaT+0rzfJyTP3LlbvvmZDv30+TOFcu2bVsAAAAGcjk9AAAAQE8IFQAAYCxCBQAAGItQAQAAxiJUAACAsQgVAABgLEIFAAAYi1ABAADG6uf0AKcrHA5r//79yszMlGVZTo8DAABiYNu2Dh8+rKFDh8rl6vl1k6QPlf3796uwsNDpMQAAwP9g7969Ovvss3t8POlDJTMzU9Kxf2hWVpbD0wAAgFgEg0EVFhZGzuM9SfpQOf52T1ZWFqECAECS+arLNriYFgAAGItQAQAAxiJUAACAsQgVAABgLEIFAAAYi1ABAADGIlQAAICxCBUAAGCspN/wDUDitfvaVLu+ToH0NLk7OlVRVi5PTq7TYwHogwgVAKekut6rDUUl8o+YHll7ummHZjY3qmZOlYOTAeiLeOsHQMyq671qKC6V3/JErfutbDUUl6q63uvQZAD6KkIFQEzafW3aUFRy7M6Xv5vDckmytbGoRO2+toTPBqDvIlQAxKR2fZ38rpyukXKc5VK7K0e16+sSOxiAPo1QARCTQHparx4HALEgVADExN3R2avHAUAsCBUAMakoK1d22CfZ4e4PsMPyhH2qKCtP7GAA+jRCBUBMPDm5mtncKMnqGit2WJKlGc2N7KcCoFcRKgBiVjOnSrN3b1K27Y9a99h+zd69iX1UAPQ6y7Zt2+khTkcwGJTb7VYgEFBWVpbT4wApgZ1pAZyuWM/fhAoAAEi4WM/fvPUDAACMRagAAABjESoAAMBYhAoAADAWoQIAAIxFqAAAAGMRKgAAwFiECgAAMBahAgAAjNXP6QEAAJD4agZ0j1ABADiuut6rDUUl8o+YHll7ummHZjY38mWXKY63fgAAjqqu96qhuFR+yxO17rey1VBcqup6r0OTwQSECgDAMe2+Nm0oKjl2x7KiH7RckmxtLCpRu68t4bPBDIQKAMAxtevr5HfldI2U4yyX2l05ql1fl9jBYAxCBQDgmEB6Wq8eh76HUAEAOMbd0dmrx6HvIVQAAI6pKCtXdtgn2eHuD7DD8oR9qigrT+xgMEZcQ+W1117TNddco6FDh8qyLL3wwgtRj9u2rUWLFumss87SwIEDNWXKFH300UfxHAkAYBBPTq5mNjdKsrrGih2WZGlGcyP7qaSwuIbK0aNHdeGFF2rlypXdPr58+XL9/Oc/V21trd58802dccYZmjZtmv7zn//EcywAgEFq5lRp9u5Nyrb9Uese26/Zuzexj0qKs2zbthPyhyxLGzdu1LXXXivp2KspQ4cO1d1336177rlHkhQIBJSfn69169bp+uuvj+n3BoNBud1uBQIBZWVlxWt8AECcsTNtaon1/O3YzrTNzc1qaWnRlClTImtut1sTJkzQ1q1bewyVUCikUCgUuR8MBuM+KwAg/jw5ubq/otrpMWAYxy6mbWlpkSTl5+dHrefn50ce647X65Xb7Y7cCgsL4zonAABwTtJ96qeqqkqBQCBy27t3r9MjAQCAOHEsVAoKCiRJra2tUeutra2Rx7qTkZGhrKysqBsAAOibHAuVoqIiFRQUaMuWLZG1YDCoN998UxMnTnRqLAAAYJC4Xkx75MgR7dq1K3K/ublZTU1N8ng8GjZsmObPn6+f/OQn+trXvqaioiI98MADGjp0aOSTQQAAILXFNVTefvttXXHFFZH7CxculCTNmjVL69at049+9CMdPXpUt99+uw4dOqRvfetb2rRpkwYMGBDPsQAAQJJI2D4q8cI+KgAAJJ9Yz99J96kfAACQOggVAABgLEIFAAAYi1ABAADGcuy7foBUxJeuAcCpIVSABKmu92pDUYn8I6ZH1p5u2qGZzY18jT0A9IC3foAEqK73qqG4VH7LE7Xut7LVUFyq6nqvQ5MBgNkIFSDO2n1t2lBUcuyOZUU/aLkk2dpYVKJ2X1vCZwMA0xEqQJzVrq+T35XTNVKOs1xqd+Wodn1dYgcDgCRAqABxFkhP69XjACCVECpAnLk7Onv1OABIJYQKEGcVZeXKDvskO9z9AXZYnrBPFWXliR0MAJIAoQLEmScnVzObGyVZXWPFDkuyNKO5kf1UAKAbhAqQADVzqjR79yZl2/6odY/t1+zdm9hHBQB6YNm2bTs9xOmI9WuiAROwMy0AHBPr+ZtQAQAACRfr+Zu3fgAAgLEIFQAAYCxCBQAAGItQAQAAxiJUAACAsQgVAABgLEIFAAAYi1ABAADGIlQAAICxCBUAAGAsQgUAABiLUAEAAMYiVAAAgLEIFQAAYCxCBQAAGItQAQAAxiJUAACAsQgVAABgLEIFAAAYi1ABAADGIlQAAICxCBUAAGAsQgUAABiLUAEAAMYiVAAAgLEcD5UHH3xQlmVF3UaOHOn0WAAAwAD9nB5AkkaPHq0//OEPkfv9+hkxFgAAp6zd16ba9XUKpKfJ3dGpirJyeXJynR4raRlRBP369VNBQYHTYwAAcFqq673aUFQi/4jpkbWnm3ZoZnOjauZUOThZ8nL8rR9J+uijjzR06FAVFxfrxhtv1J49e3o8NhQKKRgMRt0AAHBadb1XDcWl8lueqHW/la2G4lJV13sdmiy5OR4qEyZM0Lp167Rp0yatWrVKzc3Nuuyyy3T48OFuj/d6vXK73ZFbYWFhgicGACBau69NG4pKjt2xrOgHLZckWxuLStTua0v4bMnOsm3bdnqIEx06dEjDhw/XihUrNHv27C6Ph0IhhUKhyP1gMKjCwkIFAgFlZWUlclQAACRJS2pr9PMT3u7pyZ0f/D/dX1GdgInMFwwG5Xa7v/L8bcQ1KicaPHiwvv71r2vXrl3dPp6RkaGMjIwETwUAQM8C6Wm9ehy+4PhbP1925MgR/fOf/9RZZ53l9CgAAMTE3dHZq8fhC46Hyj333KNXX31VH3/8sd544w3NmDFDaWlpuuGGG5weDQCAmFSUlSs77JPscPcH2GF5wj5VlJUndrA+wPFQ+de//qUbbrhBI0aM0HXXXaecnBxt27ZNeXl5To8GAEBMPDm5mtncKMnqGit2WJKlGc2N7KfyPzDuYtpTFevFOAAAxFtkHxVXTmTNE/ZpBvuodBHr+ZtQAQCgF7EzbWwIFQAAYKxYz9+OX6MCAADQE0IFAAAYi1ABAADGIlQAAICxCBUAAGAsQgUAABiLUAEAAMYiVAAAgLEIFQAAYCxCBQAAGItQAQAAxiJUAACAsQgVAABgLEIFAAAYi1ABAADGIlQAAICxCBUAAGAsQgUAABirn9MDmKrd16ba9XUKpKfJ3dGpirJyeXJynR4LAICUQqh0o7reqw1FJfKPmB5Ze7pph2Y2N6pmTpWDkwEAkFp46+dLquu9aiguld/yRK37rWw1FJequt7r0GQAAKQeQuUE7b42bSgqOXbHsqIftFySbG0sKlG7ry3hswEAkIoIlRPUrq+T35XTNVKOs1xqd+Wodn1dYgcDACBFESonCKSn9epxAADg9BAqJ3B3dPbqcQAA4PQQKieoKCtXdtgn2eHuD7DD8oR9qigrT+xgAACkKD6efAJPTq5mNjeqobj0WKxYJ3ScHZZkaUZzozxXXeXYjKmKfW0AIDVZtm3bTg9xOoLBoNxutwKBgLKysnrld0b2UXHlRNY8YZ9msI+KI7p7PrLDPva1AYAkFuv5m1DpAf8Fb4bj+9pIiv401n9f4Zq9exOxAgBJiFBB0mv3tenSph3HNt/r7iPjdlge26/XL7qQiASAJBPr+ZuLaWEs9rUBABAqMBb72gAACBUYi31tAACECozFvjYAAEIFxjq+r41kdY2VE/e14UJaAOizCBUYrWZOlWbv3qRs2x+17rH9fDQZAFIAH09GUmBfGwDoW9hHBQAAGIt9VAAAQNIzIlRWrlypc845RwMGDNCECRPU2Njo9EgAAMAAjofK888/r4ULF2rx4sV65513dOGFF2ratGk6cOCA06MBAACHOR4qK1as0Ny5c3Xrrbdq1KhRqq2t1aBBg7RmzRqnRwMAAA5zNFQ6Ojq0fft2TZkyJbLmcrk0ZcoUbd26tdufCYVCCgaDUTcAANA3ORoqbW1t6uzsVH5+ftR6fn6+Wlpauv0Zr9crt9sduRUWFiZiVAAA4ADH3/o5VVVVVQoEApHb3r17nR4JAADEST8n/3hubq7S0tLU2toatd7a2qqCgoJufyYjI0MZGRmJGA8AADjM0VdU0tPTNW7cOG3ZsiWyFg6HtWXLFk2cONHByQAAgAkcfUVFkhYuXKhZs2Zp/PjxKikp0eOPP66jR4/q1ltvdXo0AADgMMdD5bvf/a4OHjyoRYsWqaWlRRdddJE2bdrU5QJbAACQeviuHwAAkHB81w8AAEh6hAoAADAWoQIAAIxFqAAAAGMRKgAAwFiECgAAMBahAgAAjEWoAAAAYxEqAADAWIQKAAAwFqECAACMRagAAABjESoAAMBYhAoAADAWoQIAAIxFqAAAAGMRKgAAwFiECgAAMBahAgAAjEWoAAAAYxEqAADAWIQKAAAwFqECAACMRagAAABjESoAAMBYhAoAADAWoQIAAIzVz+kBAACAedp9bapdX6dAeprcHZ2qKCuXJyc34XMQKgAAIEp1vVcbikrkHzE9svZ00w7NbG5UzZyqhM7CWz8AACCiut6rhuJS+S1P1LrfylZDcamq670JnYdQAQAAko693bOhqOTYHcuKftBySbK1sahE7b62hM1EqAAAAElS7fo6+V05XSPlOMuldleOatfXJWwmQgUAAEiSAulpvXpcbyBUAACAJMnd0dmrx/UGQgUAAEiSKsrKlR32SXa4+wPssDxhnyrKyhM2E6ECAAAkSZ6cXM1sbpRkdY0VOyzJ0ozmxoTup0KoAACAiJo5VZq9e5OybX/Uusf2a/buTQnfR8WybdtO6F/sZcFgUG63W4FAQFlZWU6PAwBAnxDvnWljPX8TKgAAIOFiPX/z1g8AADCWo6FyzjnnyLKsqNvSpUudHAkAABjE8S8lfPjhhzV37tzI/czMTAenAQAAJnE8VDIzM1VQUOD0GAAAwECOX6OydOlS5eTkaMyYMXr00Uf1+eefn/T4UCikYDAYdQMAAH2To6+o3HnnnRo7dqw8Ho/eeOMNVVVV6dNPP9WKFSt6/Bmv16uHHnoogVMCAACn9PrHkysrK7Vs2bKTHvP+++9r5MiRXdbXrFmj8vJyHTlyRBkZGd3+bCgUUigUitwPBoMqLCzk48kAACQRx/ZROXjwoHw+30mPKS4uVnp6epf19957T+eff7527typESNGxPT32EcFAIDkE+v5u9ff+snLy1NeXt7/9LNNTU1yuVwaMmRIL08FAACSkWPXqGzdulVvvvmmrrjiCmVmZmrr1q1asGCBbrrpJmVnZzs1FgAAMIhjoZKRkaHnnntODz74oEKhkIqKirRgwQItXLjQqZEAAIBhHAuVsWPHatu2bU79eQAAkAQc30cFAACgJ4QKAAAwFqECAACMRagAAABjESoAAMBYhAoAADAWoQIAAIxFqAAAAGM5tuEbEqPd16ba9XUKpKfJ3dGpirJyeXJynR4LAICYECp9WHW9VxuKSuQfMT2y9nTTDs1sblTNnCoHJwMAIDa89dNHVdd71VBcKr/liVr3W9lqKC5Vdb3XockAAIgdodIHtfvatKGo5Ngdy4p+0HJJsrWxqETtvraEzwYAwKkgVPqg2vV18rtyukbKcZZL7a4c1a6vS+xgAACcIkKlDwqkp/XqcQAAOIVQ6YPcHZ29ehwAAE4hVPqgirJyZYd9kh3u/gA7LE/Yp4qy8sQOBgDAKSJU+iBPTq5mNjdKsrrGih2WZGlGcyP7qQAAjEeo9FE1c6o0e/cmZdv+qHWP7dfs3ZvYRwUAkBQs27Ztp4c4HcFgUG63W4FAQFlZWU6PYxx2pgUAmCjW8zehAgAAEi7W8zdv/QAAAGMRKgAAwFiECgAAMBahAgAAjEWoAAAAYxEqAADAWIQKAAAwFqECAACMRagAAABjESoAAMBYhAoAADAWoQIAAIxFqAAAAGMRKgAAwFiECgAAMBahAgAAjEWoAAAAYxEqAADAWIQKAAAwFqECAACMRagAAABjxS1UampqNGnSJA0aNEiDBw/u9pg9e/Zo+vTpGjRokIYMGaJ7771Xn3/+ebxGAgAASaZfvH5xR0eHysrKNHHiRDU0NHR5vLOzU9OnT1dBQYHeeOMNffrpp7r55pvVv39/LVmyJF5jAQCAJGLZtm3H8w+sW7dO8+fP16FDh6LWX3rpJV199dXav3+/8vPzJUm1tbW67777dPDgQaWnp8f0+4PBoNxutwKBgLKysnp7fAAAEAexnr8du0Zl69atuuCCCyKRIknTpk1TMBjUe++91+PPhUIhBYPBqBsAAOibHAuVlpaWqEiRFLnf0tLS4895vV653e7IrbCwMK5zAgAA55xSqFRWVsqyrJPedu7cGa9ZJUlVVVUKBAKR2969e+P69wAAgHNO6WLau+++W7fccstJjykuLo7pdxUUFKixsTFqrbW1NfJYTzIyMpSRkRHT3wAAAMntlEIlLy9PeXl5vfKHJ06cqJqaGh04cEBDhgyRJG3evFlZWVkaNWpUr/wNADiZdl+batfXKZCeJndHpyrKyuXJyXV6LAAniNvHk/fs2aP29nbt2bNHnZ2dampqkiSdd955OvPMMzV16lSNGjVK3/ve97R8+XK1tLToxz/+sebNm8crJgDirrreqw1FJfKPmB5Ze7pph2Y2N6pmTpWDkwE4Udw+nnzLLbfoqaee6rL+yiuvaPLkyZKkTz75RN///vf1pz/9SWeccYZmzZqlpUuXql+/2PuJjycDOFXV9V41FJceu2NZXzxghyVZmr17E7ECxFms5++476MSb4QKgFPR7mvTpU075Lc80ZFynB2Wx/br9Ysu5G0gII6M30cFAJxQu75OfldO95EiSZZL7a4c1a6vS+xgALpFqABIKYH0tF49DkB8ESoAUoq7o7NXjwMQX4QKgJRSUVau7LDvvxfOdsMOyxP2qaKsPLGDAegWoQIgpXhycjWzuVGS1TVW/vupnxnNjVxICxiCUAGQcmrmVGn27k3Ktv1R6x7bz0eTAcPw8WQAKYudaQHnsI8KAAAwFvuoAACApEeoAAAAYxEqAADAWIQKAAAwFqECAACMRagAAABjESoAAMBYhAoAADAWoQIAAIxFqAAAAGMRKgAAwFiECgAAMBahAgAAjEWoAAAAYxEqAADAWIQKAAAwFqECAACMRagAAABjESoAAMBYhAoAADAWoQIAAIxFqAAAAGMRKgAAwFiECgAAMBahAgAAjEWoAAAAYxEqAADAWIQKAAAwFqECAACMRagAAABjESoAAMBYhAoAADAWoQIAAIwVt1CpqanRpEmTNGjQIA0ePLjbYyzL6nJ77rnn4jUSAABIMv3i9Ys7OjpUVlamiRMnqqGhocfj1q5dq9LS0sj9nqIGAACknriFykMPPSRJWrdu3UmPGzx4sAoKCuI1BgAASGKOX6Myb9485ebmqqSkRGvWrJFt2yc9PhQKKRgMRt0AAEDfFLdXVGLx8MMP68orr9SgQYP08ssv6wc/+IGOHDmiO++8s8ef8Xq9kVdrAABA32bZX/USxgkqKyu1bNmykx7z/vvva+TIkZH769at0/z583Xo0KGv/P2LFi3S2rVrtXfv3h6PCYVCCoVCkfvBYFCFhYUKBALKysr66n8EAABwXDAYlNvt/srz9ym9onL33XfrlltuOekxxcXFp/Iro0yYMEGPPPKIQqGQMjIyuj0mIyOjx8cAAEDfckqhkpeXp7y8vHjNoqamJmVnZxMiAABAUhyvUdmzZ4/a29u1Z88edXZ2qqmpSZJ03nnn6cwzz9SLL76o1tZWXXLJJRowYIA2b96sJUuW6J577onXSAAAIMnELVQWLVqkp556KnJ/zJgxkqRXXnlFkydPVv/+/bVy5UotWLBAtm3rvPPO04oVKzR37tx4jQQAAJLMKV1Ma6JYL8YBAADmiPX87fg+KgAAAD0hVAAAgLEIFQAAYCxCBQAAGItQAQAAxiJUAACAsQgVAABgLEIFAAAYi1ABAADGIlQAAICxCBUAAGAsQgUAABiLUAEAAMYiVAAAgLEIFQAAYCxCBQAAGItQAQAAxiJUAACAsQgVAABgLEIFAAAYi1ABAADGIlQAAICxCBUAAGAsQgUAABiLUAEAAMYiVAAAgLEIFQAAYCxCBQAAGItQAQAAxiJUAACAsQgVAABgLEIFAAAYi1ABAADGIlQAAICxCBUAAGAsQgUAABiLUAEAAMbq5/QAAIDT0+5rU+36OgXS0+Tu6FRFWbk8OblOjwX0CkIFAJJYdb1XG4pK5B8xPbL2dNMOzWxuVM2cKgcnA3oHb/0AQJKqrveqobhUfssTte63stVQXKrqeq9DkwG9J26h8vHHH2v27NkqKirSwIEDde6552rx4sXq6OiIOu5vf/ubLrvsMg0YMECFhYVavnx5vEYCgD6j3demDUUlx+5YVvSDlkuSrY1FJWr3tSV8NqA3xS1Udu7cqXA4rLq6Or333nt67LHHVFtbq/vvvz9yTDAY1NSpUzV8+HBt375djz76qB588EGtXr06XmMBQJ9Qu75OfldO10g5znKp3ZWj2vV1iR0M6GVxu0altLRUpaWlkfvFxcX64IMPtGrVKv30pz+VJD3zzDPq6OjQmjVrlJ6ertGjR6upqUkrVqzQ7bffHq/RACDpBdLTevU4wFQJvUYlEAjI4/nivdStW7fq8ssvV3p6emRt2rRp+uCDD+T3+xM5GgAkFXdHZ68eB5gqYaGya9cuPfHEEyovL4+stbS0KD8/P+q44/dbWlq6/T2hUEjBYDDqBgCppqKsXNlhn2SHuz/ADssT9qmirLz7x4EkccqhUllZKcuyTnrbuXNn1M/s27dPpaWlKisr09y5c09rYK/XK7fbHbkVFhae1u8DgGTkycnVzOZGSVbXWLHDkizNaG5kPxUkPcu2bftUfuDgwYPy+XwnPaa4uDjyds7+/fs1efJkXXLJJVq3bp1cri/a6Oabb1YwGNQLL7wQWXvllVd05ZVXqr29XdnZ2V1+dygUUigUitwPBoMqLCxUIBBQVlbWqfxTACDpRfZRceVE1jxhn2awjwoMFwwG5Xa7v/L8fcoX0+bl5SkvLy+mY/ft26crrrhC48aN09q1a6MiRZImTpyo6upqffbZZ+rfv78kafPmzRoxYkS3kSJJGRkZysjIONWxAaBPqplTpbu725n2qqucHg3oFaf8ikqs9u3bp8mTJ2v48OF66qmnlJb2xZXnBQUFko5dXDtixAhNnTpV9913n959913ddttteuyxx2L+1E+sRQYAAMwRt1dUYrV582bt2rVLu3bt0tlnnx312PE2crvdevnllzVv3jyNGzdOubm5WrRoER9NBgAAkuL4ikqi8IoKAADJJ9bzN9/1AwAAjEWoAAAAYxEqAADAWIQKAAAwFqECAACMRagAAABjESoAAMBYcdvwLVGObwPDtygDAJA8jp+3v2o7t6QPlcOHD0sS36IMAEASOnz4sNxud4+PJ/3OtOFwWPv371dmZqYsy+rV3338m5n37t3LrrcG4PkwC8+HWXg+zMLz8dVs29bhw4c1dOjQLl9afKKkf0XF5XJ1+S6h3paVlcX/0AzC82EWng+z8HyYhefj5E72SspxXEwLAACMRagAAABjESonkZGRocWLFysjI8PpUSCeD9PwfJiF58MsPB+9J+kvpgUAAH0Xr6gAAABjESoAAMBYhAoAADAWoQIAAIxFqPRg5cqVOuecczRgwABNmDBBjY2NTo+Ukrxery6++GJlZmZqyJAhuvbaa/XBBx84PRb+a+nSpbIsS/Pnz3d6lJS2b98+3XTTTcrJydHAgQN1wQUX6O2333Z6rJTU2dmpBx54QEVFRRo4cKDOPfdcPfLII1/5fTboGaHSjeeff14LFy7U4sWL9c477+jCCy/UtGnTdODAAadHSzmvvvqq5s2bp23btmnz5s367LPPNHXqVB09etTp0VLeW2+9pbq6On3zm990epSU5vf7demll6p///566aWX9I9//EM/+9nPlJ2d7fRoKWnZsmVatWqVnnzySb3//vtatmyZli9frieeeMLp0ZIWH0/uxoQJE3TxxRfrySeflHTs+4QKCwv1wx/+UJWVlQ5Pl9oOHjyoIUOG6NVXX9Xll1/u9Dgp68iRIxo7dqx+8Ytf6Cc/+YkuuugiPf74406PlZIqKyv1l7/8RX/+85+dHgWSrr76auXn56uhoSGy9p3vfEcDBw7Ur371KwcnS168ovIlHR0d2r59u6ZMmRJZc7lcmjJlirZu3ergZJCkQCAgSfJ4PA5PktrmzZun6dOnR/3/BM743e9+p/Hjx6usrExDhgzRmDFj9Mtf/tLpsVLWpEmTtGXLFn344YeSpB07duj111/Xt7/9bYcnS15J/6WEva2trU2dnZ3Kz8+PWs/Pz9fOnTsdmgrSsVe25s+fr0svvVTnn3++0+OkrOeee07vvPOO3nrrLadHgaTdu3dr1apVWrhwoe6//3699dZbuvPOO5Wenq5Zs2Y5PV7KqaysVDAY1MiRI5WWlqbOzk7V1NToxhtvdHq0pEWoIGnMmzdP7777rl5//XWnR0lZe/fu1V133aXNmzdrwIABTo8DHQv48ePHa8mSJZKkMWPG6N1331VtbS2h4oBf//rXeuaZZ/Tss89q9OjRampq0vz58zV06FCej/8RofIlubm5SktLU2tra9R6a2urCgoKHJoKd9xxh37/+9/rtdde09lnn+30OClr+/btOnDggMaOHRtZ6+zs1GuvvaYnn3xSoVBIaWlpDk6Yes466yyNGjUqau0b3/iGfvOb3zg0UWq79957VVlZqeuvv16SdMEFF+iTTz6R1+slVP5HXKPyJenp6Ro3bpy2bNkSWQuHw9qyZYsmTpzo4GSpybZt3XHHHdq4caP++Mc/qqioyOmRUtpVV12lv//972pqaorcxo8frxtvvFFNTU1EigMuvfTSLh/Z//DDDzV8+HCHJkpt//73v+VyRZ9a09LSFA6HHZoo+fGKSjcWLlyoWbNmafz48SopKdHjjz+uo0eP6tZbb3V6tJQzb948Pfvss/rtb3+rzMxMtbS0SJLcbrcGDhzo8HSpJzMzs8v1QWeccYZycnK4bsghCxYs0KRJk7RkyRJdd911amxs1OrVq7V69WqnR0tJ11xzjWpqajRs2DCNHj1af/3rX7VixQrddtttTo+WvGx064knnrCHDRtmp6en2yUlJfa2bducHiklSer2tnbtWqdHw3/93//9n33XXXc5PUZKe/HFF+3zzz/fzsjIsEeOHGmvXr3a6ZFSVjAYtO+66y572LBh9oABA+zi4mK7urraDoVCTo+WtNhHBQAAGItrVAAAgLEIFQAAYCxCBQAAGItQAQAAxiJUAACAsQgVAABgLEIFAAAYi1ABAADGIlQAAICxCBUAAGAsQgUAABiLUAEAAMb6/2rRE46/O89BAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl4tDuMxGf2F"
      },
      "source": [
        "### 슬롯머신 풀어보기\n",
        "\n",
        "직접 위 환경과 상호작용하면서, 각 슬롯머신의 보상을 추정해보세요. 그리고 Python을 이용해 위 문제에서 $\\epsilon=0.1$과 $\\epsilon=0.01$에 대해 각각 $\\epsilon$-greedy 방법을 적용해 보세요. (초기값 $Q_{1}(i)$는 모두 0으로 설정.) 또한 $Q_{1}(i) = 5$인 완전 탐욕적인 알고리즘 ($\\epsilon=0$) 또한 Python으로 구현하여 그 결과를 비교해 보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5Pc0yv7Gf2F"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class EpsilonGreedyPolicy:\n",
        "    def __init__(self, num_bandits, epsilon):\n",
        "        self.num_bandits = num_bandits\n",
        "        self.epsilon = epsilon\n",
        "        ????\n",
        "\n",
        "    def select_action(self):\n",
        "        action = ????\n",
        "        return action\n",
        "\n",
        "\n",
        "env = BanditEnv(10)\n",
        "policy = EpsilonGreedyPolicy(10, 0.1)\n",
        "\n",
        "state = env.reset()\n",
        "total_reward = 0\n",
        "for t in range(100):\n",
        "    action = policy.select_action()\n",
        "    state, reward, done, _ = env.step(action)\n",
        "    print(\"Action:\", action, \"Reward:\", reward)\n",
        "    total_reward += reward\n",
        "\n",
        "print(\"Total reward:\", total_reward)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rllib",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DuDaRw3aGf17"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}